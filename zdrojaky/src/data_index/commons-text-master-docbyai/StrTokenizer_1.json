[
    {
        "signature": "private static StrTokenizer getCSVClone()",
        "implementation": "private static StrTokenizer getCSVClone() {\n        return (StrTokenizer) CSV_TOKENIZER_PROTOTYPE.clone();\n    }",
        "called_methods": [
            "clone"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getCSVClone",
        "javadoc": "/**\n     * Returns a clone of {@code CSV_TOKENIZER_PROTOTYPE}.\n     *\n     * @return a clone of {@code CSV_TOKENIZER_PROTOTYPE}.\n     */"
    },
    {
        "signature": "public static StrTokenizer getCSVInstance(final String input)",
        "implementation": "public static StrTokenizer getCSVInstance(final String input) {\n        final StrTokenizer tok = getCSVClone();\n        tok.reset(input);\n        return tok;\n    }",
        "called_methods": [
            "getCSVClone",
            "reset"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getCSVInstance",
        "javadoc": "/**\n     * Gets a new tokenizer instance which parses Comma Separated Value strings\n     * initializing it with the given input.  The default for CSV processing\n     * will be trim whitespace from both ends (which can be overridden with\n     * the setTrimmer method).\n     *\n     * @param input  the text to parse\n     * @return a new tokenizer instance which parses Comma Separated Value strings\n     */"
    },
    {
        "signature": "private static StrTokenizer getTSVClone()",
        "implementation": "private static StrTokenizer getTSVClone() {\n        return (StrTokenizer) TSV_TOKENIZER_PROTOTYPE.clone();\n    }",
        "called_methods": [
            "clone"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getTSVClone",
        "javadoc": "/**\n     * Returns a clone of {@code TSV_TOKENIZER_PROTOTYPE}.\n     *\n     * @return a clone of {@code TSV_TOKENIZER_PROTOTYPE}.\n     */"
    },
    {
        "signature": "public static StrTokenizer getTSVInstance(final String input)",
        "implementation": "public static StrTokenizer getTSVInstance(final String input) {\n        final StrTokenizer tok = getTSVClone();\n        tok.reset(input);\n        return tok;\n    }",
        "called_methods": [
            "getTSVClone",
            "reset"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getTSVInstance",
        "javadoc": "/**\n     * Gets a new tokenizer instance which parses Tab Separated Value strings.\n     * The default for CSV processing will be trim whitespace from both ends\n     * (which can be overridden with the setTrimmer method).\n     * @param input  the string to parse\n     * @return a new tokenizer instance which parses Tab Separated Value strings.\n     */"
    },
    {
        "signature": "public void add(final String obj)",
        "implementation": "public void add(final String obj) {\n        throw new UnsupportedOperationException(\"add() is unsupported\");\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "add",
        "javadoc": "/**\n     * Unsupported ListIterator operation.\n     * @param obj this parameter ignored.\n     * @throws UnsupportedOperationException always\n     */"
    },
    {
        "signature": "private void addToken(final List<String> list, String tok)",
        "implementation": "private void addToken(final List<String> list, String tok) {\n        if (tok == null || tok.isEmpty()) {\n            if (isIgnoreEmptyTokens()) {\n                return;\n            }\n            if (isEmptyTokenAsNull()) {\n                tok = null;\n            }\n        }\n        list.add(tok);\n    }",
        "called_methods": [
            "isEmpty",
            "isIgnoreEmptyTokens",
            "isEmptyTokenAsNull",
            "add"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "addToken",
        "javadoc": "/**\n     * Adds a token to a list, paying attention to the parameters we've set.\n     *\n     * @param list  the list to add to\n     * @param tok  the token to add\n     */"
    },
    {
        "signature": "private void checkTokenized()",
        "implementation": "private void checkTokenized() {\n        if (tokens == null) {\n            if (chars == null) {\n                // still call tokenize as subclass may do some work\n                final List<String> split = tokenize(null, 0, 0);\n                tokens = split.toArray(ArrayUtils.EMPTY_STRING_ARRAY);\n            } else {\n                final List<String> split = tokenize(chars, 0, chars.length);\n                tokens = split.toArray(ArrayUtils.EMPTY_STRING_ARRAY);\n            }\n        }\n    }",
        "called_methods": [
            "tokenize",
            "toArray"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "checkTokenized",
        "javadoc": "/**\n     * Checks if tokenization has been done, and if not then do it.\n     */"
    },
    {
        "signature": "public Object clone()",
        "implementation": "public Object clone() {\n        try {\n            return cloneReset();\n        } catch (final CloneNotSupportedException ex) {\n            return null;\n        }\n    }",
        "called_methods": [
            "cloneReset"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "clone",
        "javadoc": "/**\n     * Creates a new instance of this Tokenizer. The new instance is reset so\n     * that it will be at the start of the token list.\n     * If a {@link CloneNotSupportedException} is caught, return {@code null}.\n     *\n     * @return a new instance of this Tokenizer which has been reset.\n     */"
    },
    {
        "signature": "Object cloneReset() throws CloneNotSupportedException",
        "implementation": "Object cloneReset() throws CloneNotSupportedException {\n        // this method exists to enable 100% test coverage\n        final StrTokenizer cloned = (StrTokenizer) super.clone();\n        if (cloned.chars != null) {\n            cloned.chars = cloned.chars.clone();\n        }\n        cloned.reset();\n        return cloned;\n    }",
        "called_methods": [
            "clone",
            "reset"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "cloneReset",
        "javadoc": "/**\n     * Creates a new instance of this Tokenizer. The new instance is reset so that\n     * it will be at the start of the token list.\n     *\n     * @return a new instance of this Tokenizer which has been reset.\n     * @throws CloneNotSupportedException if there is a problem cloning\n     */"
    },
    {
        "signature": "public String getContent()",
        "implementation": "public String getContent() {\n        if (chars == null) {\n            return null;\n        }\n        return new String(chars);\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getContent",
        "javadoc": "/**\n     * Gets the String content that the tokenizer is parsing.\n     *\n     * @return The string content being parsed\n     */"
    },
    {
        "signature": "public StrMatcher getDelimiterMatcher()",
        "implementation": "public StrMatcher getDelimiterMatcher() {\n        return this.delimMatcher;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getDelimiterMatcher",
        "javadoc": "/**\n     * Gets the field delimiter matcher.\n     *\n     * @return The delimiter matcher in use\n     */"
    },
    {
        "signature": "public StrMatcher getIgnoredMatcher()",
        "implementation": "public StrMatcher getIgnoredMatcher() {\n        return ignoredMatcher;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getIgnoredMatcher",
        "javadoc": "/**\n     * Gets the ignored character matcher.\n     * <p>\n     * These characters are ignored when parsing the String, unless they are\n     * within a quoted region.\n     * The default value is not to ignore anything.\n     * </p>\n     *\n     * @return The ignored matcher in use\n     */"
    },
    {
        "signature": "public StrMatcher getQuoteMatcher()",
        "implementation": "public StrMatcher getQuoteMatcher() {\n        return quoteMatcher;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getQuoteMatcher",
        "javadoc": "/**\n     * Gets the quote matcher currently in use.\n     * <p>\n     * The quote character is used to wrap data between the tokens.\n     * This enables delimiters to be entered as data.\n     * The default value is '\"' (double quote).\n     * </p>\n     *\n     * @return The quote matcher in use\n     */"
    },
    {
        "signature": "public String[] getTokenArray()",
        "implementation": "public String[] getTokenArray() {\n        checkTokenized();\n        return tokens.clone();\n    }",
        "called_methods": [
            "checkTokenized",
            "clone"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getTokenArray",
        "javadoc": "/**\n     * Gets a copy of the full token list as an independent modifiable array.\n     *\n     * @return The tokens as a String array\n     */"
    },
    {
        "signature": "public List<String> getTokenList()",
        "implementation": "public List<String> getTokenList() {\n        checkTokenized();\n        final List<String> list = new ArrayList<>(tokens.length);\n        Collections.addAll(list, tokens);\n\n        return list;\n    }",
        "called_methods": [
            "checkTokenized",
            "addAll"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getTokenList",
        "javadoc": "/**\n     * Gets a copy of the full token list as an independent modifiable list.\n     *\n     * @return The tokens as a String array\n     */"
    },
    {
        "signature": "public StrMatcher getTrimmerMatcher()",
        "implementation": "public StrMatcher getTrimmerMatcher() {\n        return trimmerMatcher;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "getTrimmerMatcher",
        "javadoc": "/**\n     * Gets the trimmer character matcher.\n     * <p>\n     * These characters are trimmed off on each side of the delimiter\n     * until the token or quote is found.\n     * The default value is not to trim anything.\n     * </p>\n     *\n     * @return The trimmer matcher in use\n     */"
    },
    {
        "signature": "public boolean hasNext()",
        "implementation": "public boolean hasNext() {\n        checkTokenized();\n        return tokenPos < tokens.length;\n    }",
        "called_methods": [
            "checkTokenized"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "hasNext",
        "javadoc": "/**\n     * Checks whether there are any more tokens.\n     *\n     * @return true if there are more tokens\n     */"
    },
    {
        "signature": "public boolean hasPrevious()",
        "implementation": "public boolean hasPrevious() {\n        checkTokenized();\n        return tokenPos > 0;\n    }",
        "called_methods": [
            "checkTokenized"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "hasPrevious",
        "javadoc": "/**\n     * Checks whether there are any previous tokens that can be iterated to.\n     *\n     * @return true if there are previous tokens\n     */"
    },
    {
        "signature": "public boolean isEmptyTokenAsNull()",
        "implementation": "public boolean isEmptyTokenAsNull() {\n        return this.emptyAsNull;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "isEmptyTokenAsNull",
        "javadoc": "/**\n     * Gets whether the tokenizer currently returns empty tokens as null.\n     * The default for this property is false.\n     *\n     * @return true if empty tokens are returned as null\n     */"
    },
    {
        "signature": "public boolean isIgnoreEmptyTokens()",
        "implementation": "public boolean isIgnoreEmptyTokens() {\n        return ignoreEmptyTokens;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "isIgnoreEmptyTokens",
        "javadoc": "/**\n     * Gets whether the tokenizer currently ignores empty tokens.\n     * The default for this property is true.\n     *\n     * @return true if empty tokens are not returned\n     */"
    },
    {
        "signature": "private boolean isQuote(final char[] srcChars,\n                            final int pos,\n                            final int len,\n                            final int quoteStart,\n                            final int quoteLen)",
        "implementation": "private boolean isQuote(final char[] srcChars,\n                            final int pos,\n                            final int len,\n                            final int quoteStart,\n                            final int quoteLen) {\n        for (int i = 0; i < quoteLen; i++) {\n            if (pos + i >= len || srcChars[pos + i] != srcChars[quoteStart + i]) {\n                return false;\n            }\n        }\n        return true;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "isQuote",
        "javadoc": "/**\n     * Checks if the characters at the index specified match the quote\n     * already matched in readNextToken().\n     *\n     * @param srcChars  the character array being tokenized\n     * @param pos  the position to check for a quote\n     * @param len  the length of the character array being tokenized\n     * @param quoteStart  the start position of the matched quote, 0 if no quoting\n     * @param quoteLen  the length of the matched quote, 0 if no quoting\n     * @return true if a quote is matched\n     */"
    },
    {
        "signature": "public String next()",
        "implementation": "public String next() {\n        if (hasNext()) {\n            return tokens[tokenPos++];\n        }\n        throw new NoSuchElementException();\n    }",
        "called_methods": [
            "hasNext"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "next",
        "javadoc": "/**\n     * Gets the next token.\n     *\n     * @return The next String token\n     * @throws NoSuchElementException if there are no more elements\n     */"
    },
    {
        "signature": "public int nextIndex()",
        "implementation": "public int nextIndex() {\n        return tokenPos;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "nextIndex",
        "javadoc": "/**\n     * Gets the index of the next token to return.\n     *\n     * @return The next token index\n     */"
    },
    {
        "signature": "public String nextToken()",
        "implementation": "public String nextToken() {\n        if (hasNext()) {\n            return tokens[tokenPos++];\n        }\n        return null;\n    }",
        "called_methods": [
            "hasNext"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "nextToken",
        "javadoc": "/**\n     * Gets the next token from the String.\n     * Equivalent to {@link #next()} except it returns null rather than\n     * throwing {@link NoSuchElementException} when no tokens remain.\n     *\n     * @return The next sequential token, or null when no more tokens are found\n     */"
    },
    {
        "signature": "public String previous()",
        "implementation": "public String previous() {\n        if (hasPrevious()) {\n            return tokens[--tokenPos];\n        }\n        throw new NoSuchElementException();\n    }",
        "called_methods": [
            "hasPrevious"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "previous",
        "javadoc": "/**\n     * Gets the token previous to the last returned token.\n     *\n     * @return The previous token\n     */"
    },
    {
        "signature": "public int previousIndex()",
        "implementation": "public int previousIndex() {\n        return tokenPos - 1;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "previousIndex",
        "javadoc": "/**\n     * Gets the index of the previous token.\n     *\n     * @return The previous token index\n     */"
    },
    {
        "signature": "public String previousToken()",
        "implementation": "public String previousToken() {\n        if (hasPrevious()) {\n            return tokens[--tokenPos];\n        }\n        return null;\n    }",
        "called_methods": [
            "hasPrevious"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "previousToken",
        "javadoc": "/**\n     * Gets the previous token from the String.\n     *\n     * @return The previous sequential token, or null when no more tokens are found\n     */"
    },
    {
        "signature": "private int readNextToken(final char[] srcChars,\n                              int start,\n                              final int len,\n                              final StrBuilder workArea,\n                              final List<String> tokenList)",
        "implementation": "private int readNextToken(final char[] srcChars,\n                              int start,\n                              final int len,\n                              final StrBuilder workArea,\n                              final List<String> tokenList) {\n        // skip all leading whitespace, unless it is the\n        // field delimiter or the quote character\n        while (start < len) {\n            final int removeLen = Math.max(\n                    getIgnoredMatcher().isMatch(srcChars, start, start, len),\n                    getTrimmerMatcher().isMatch(srcChars, start, start, len));\n            if (removeLen == 0\n                    || getDelimiterMatcher().isMatch(srcChars, start, start, len) > 0\n                    || getQuoteMatcher().isMatch(srcChars, start, start, len) > 0) {\n                break;\n            }\n            start += removeLen;\n        }\n\n        // handle reaching end\n        if (start >= len) {\n            addToken(tokenList, StringUtils.EMPTY);\n            return -1;\n        }\n\n        // handle empty token\n        final int delimLen = getDelimiterMatcher().isMatch(srcChars, start, start, len);\n        if (delimLen > 0) {\n            addToken(tokenList, StringUtils.EMPTY);\n            return start + delimLen;\n        }\n\n        // handle found token\n        final int quoteLen = getQuoteMatcher().isMatch(srcChars, start, start, len);\n        if (quoteLen > 0) {\n            return readWithQuotes(srcChars, start + quoteLen, len, workArea, tokenList, start, quoteLen);\n        }\n        return readWithQuotes(srcChars, start, len, workArea, tokenList, 0, 0);\n    }",
        "called_methods": [
            "max",
            "getIgnoredMatcher",
            "isMatch",
            "getTrimmerMatcher",
            "getDelimiterMatcher",
            "getQuoteMatcher",
            "addToken",
            "readWithQuotes"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "readNextToken",
        "javadoc": "/**\n     * Reads character by character through the String to get the next token.\n     *\n     * @param srcChars  the character array being tokenized\n     * @param start  the first character of field\n     * @param len  the length of the character array being tokenized\n     * @param workArea  a temporary work area\n     * @param tokenList  the list of parsed tokens\n     * @return The starting position of the next field (the character\n     *  immediately after the delimiter), or -1 if end of string found\n     */"
    },
    {
        "signature": "private int readWithQuotes(final char[] srcChars, final int start, final int len, final StrBuilder workArea,\n                               final List<String> tokenList, final int quoteStart, final int quoteLen)",
        "implementation": "private int readWithQuotes(final char[] srcChars, final int start, final int len, final StrBuilder workArea,\n                               final List<String> tokenList, final int quoteStart, final int quoteLen) {\n        // Loop until we've found the end of the quoted\n        // string or the end of the input\n        workArea.clear();\n        int pos = start;\n        boolean quoting = quoteLen > 0;\n        int trimStart = 0;\n\n        while (pos < len) {\n            // quoting mode can occur several times throughout a string\n            // we must switch between quoting and non-quoting until we\n            // encounter a non-quoted delimiter, or end of string\n            if (quoting) {\n                // In quoting mode\n\n                // If we've found a quote character, see if it's\n                // followed by a second quote.  If so, then we need\n                // to actually put the quote character into the token\n                // rather than end the token.\n                if (isQuote(srcChars, pos, len, quoteStart, quoteLen)) {\n                    if (isQuote(srcChars, pos + quoteLen, len, quoteStart, quoteLen)) {\n                        // matched pair of quotes, thus an escaped quote\n                        workArea.append(srcChars, pos, quoteLen);\n                        pos += quoteLen * 2;\n                        trimStart = workArea.size();\n                        continue;\n                    }\n\n                    // end of quoting\n                    quoting = false;\n                    pos += quoteLen;\n                    continue;\n                }\n\n            } else {\n                // Not in quoting mode\n\n                // check for delimiter, and thus end of token\n                final int delimLen = getDelimiterMatcher().isMatch(srcChars, pos, start, len);\n                if (delimLen > 0) {\n                    // return condition when end of token found\n                    addToken(tokenList, workArea.substring(0, trimStart));\n                    return pos + delimLen;\n                }\n\n                // check for quote, and thus back into quoting mode\n                if (quoteLen > 0 && isQuote(srcChars, pos, len, quoteStart, quoteLen)) {\n                    quoting = true;\n                    pos += quoteLen;\n                    continue;\n                }\n\n                // check for ignored (outside quotes), and ignore\n                final int ignoredLen = getIgnoredMatcher().isMatch(srcChars, pos, start, len);\n                if (ignoredLen > 0) {\n                    pos += ignoredLen;\n                    continue;\n                }\n\n                // check for trimmed character\n                // don't yet know if its at the end, so copy to workArea\n                // use trimStart to keep track of trim at the end\n                final int trimmedLen = getTrimmerMatcher().isMatch(srcChars, pos, start, len);\n                if (trimmedLen > 0) {\n                    workArea.append(srcChars, pos, trimmedLen);\n                    pos += trimmedLen;\n                    continue;\n                }\n\n            }\n            // copy regular character from inside quotes\n            workArea.append(srcChars[pos++]);\n            trimStart = workArea.size();\n        }\n\n        // return condition when end of string found\n        addToken(tokenList, workArea.substring(0, trimStart));\n        return -1;\n    }",
        "called_methods": [
            "clear",
            "isQuote",
            "append",
            "size",
            "getDelimiterMatcher",
            "isMatch",
            "addToken",
            "substring",
            "getIgnoredMatcher",
            "getTrimmerMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "readWithQuotes",
        "javadoc": "/**\n     * Reads a possibly quoted string token.\n     *\n     * @param srcChars  the character array being tokenized\n     * @param start  the first character of field\n     * @param len  the length of the character array being tokenized\n     * @param workArea  a temporary work area\n     * @param tokenList  the list of parsed tokens\n     * @param quoteStart  the start position of the matched quote, 0 if no quoting\n     * @param quoteLen  the length of the matched quote, 0 if no quoting\n     * @return The starting position of the next field (the character\n     *  immediately after the delimiter, or if end of string found,\n     *  then the length of string\n     */"
    },
    {
        "signature": "public void remove()",
        "implementation": "public void remove() {\n        throw new UnsupportedOperationException(\"remove() is unsupported\");\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "remove",
        "javadoc": "/**\n     * Unsupported ListIterator operation.\n     *\n     * @throws UnsupportedOperationException always\n     */"
    },
    {
        "signature": "public StrTokenizer reset(final String input)",
        "implementation": "public StrTokenizer reset(final String input) {\n        reset();\n        if (input != null) {\n            this.chars = input.toCharArray();\n        } else {\n            this.chars = null;\n        }\n        return this;\n    }",
        "called_methods": [
            "reset",
            "clone",
            "toCharArray"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "reset",
        "javadoc": "/**\n     * Reset this tokenizer, giving it a new input string to parse.\n     * In this manner you can re-use a tokenizer with the same settings\n     * on multiple input lines.\n     *\n     * @param input  the new string to tokenize, null sets no text to parse\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public void set(final String obj)",
        "implementation": "public void set(final String obj) {\n        throw new UnsupportedOperationException(\"set() is unsupported\");\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "set",
        "javadoc": "/**\n     * Unsupported ListIterator operation.\n     * @param obj this parameter ignored.\n     * @throws UnsupportedOperationException always\n     */"
    },
    {
        "signature": "public StrTokenizer setDelimiterChar(final char delim)",
        "implementation": "public StrTokenizer setDelimiterChar(final char delim) {\n        return setDelimiterMatcher(StrMatcher.charMatcher(delim));\n    }",
        "called_methods": [
            "setDelimiterMatcher",
            "charMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setDelimiterChar",
        "javadoc": "/**\n     * Sets the field delimiter character.\n     *\n     * @param delim  the delimiter character to use\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setDelimiterMatcher(final StrMatcher delim)",
        "implementation": "public StrTokenizer setDelimiterMatcher(final StrMatcher delim) {\n        if (delim == null) {\n            this.delimMatcher = StrMatcher.noneMatcher();\n        } else {\n            this.delimMatcher = delim;\n        }\n        return this;\n    }",
        "called_methods": [
            "noneMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setDelimiterMatcher",
        "javadoc": "/**\n     * Sets the field delimiter matcher.\n     * <p>\n     * The delimiter is used to separate one token from another.\n     * </p>\n     *\n     * @param delim  the delimiter matcher to use\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setDelimiterString(final String delim)",
        "implementation": "public StrTokenizer setDelimiterString(final String delim) {\n        return setDelimiterMatcher(StrMatcher.stringMatcher(delim));\n    }",
        "called_methods": [
            "setDelimiterMatcher",
            "stringMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setDelimiterString",
        "javadoc": "/**\n     * Sets the field delimiter string.\n     *\n     * @param delim  the delimiter string to use\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setEmptyTokenAsNull(final boolean emptyAsNull)",
        "implementation": "public StrTokenizer setEmptyTokenAsNull(final boolean emptyAsNull) {\n        this.emptyAsNull = emptyAsNull;\n        return this;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setEmptyTokenAsNull",
        "javadoc": "/**\n     * Sets whether the tokenizer should return empty tokens as null.\n     * The default for this property is false.\n     *\n     * @param emptyAsNull  whether empty tokens are returned as null\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setIgnoredChar(final char ignored)",
        "implementation": "public StrTokenizer setIgnoredChar(final char ignored) {\n        return setIgnoredMatcher(StrMatcher.charMatcher(ignored));\n    }",
        "called_methods": [
            "setIgnoredMatcher",
            "charMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setIgnoredChar",
        "javadoc": "/**\n     * Sets the character to ignore.\n     * <p>\n     * This character is ignored when parsing the String, unless it is\n     * within a quoted region.\n     * </p>\n     *\n     * @param ignored  the ignored character to use\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setIgnoredMatcher(final StrMatcher ignored)",
        "implementation": "public StrTokenizer setIgnoredMatcher(final StrMatcher ignored) {\n        if (ignored != null) {\n            this.ignoredMatcher = ignored;\n        }\n        return this;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setIgnoredMatcher",
        "javadoc": "/**\n     * Sets the matcher for characters to ignore.\n     * <p>\n     * These characters are ignored when parsing the String, unless they are\n     * within a quoted region.\n     * </p>\n     *\n     * @param ignored  the ignored matcher to use, null ignored\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setIgnoreEmptyTokens(final boolean ignoreEmptyTokens)",
        "implementation": "public StrTokenizer setIgnoreEmptyTokens(final boolean ignoreEmptyTokens) {\n        this.ignoreEmptyTokens = ignoreEmptyTokens;\n        return this;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setIgnoreEmptyTokens",
        "javadoc": "/**\n     * Sets whether the tokenizer should ignore and not return empty tokens.\n     * The default for this property is true.\n     *\n     * @param ignoreEmptyTokens  whether empty tokens are not returned\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setQuoteChar(final char quote)",
        "implementation": "public StrTokenizer setQuoteChar(final char quote) {\n        return setQuoteMatcher(StrMatcher.charMatcher(quote));\n    }",
        "called_methods": [
            "setQuoteMatcher",
            "charMatcher"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setQuoteChar",
        "javadoc": "/**\n     * Sets the quote character to use.\n     * <p>\n     * The quote character is used to wrap data between the tokens.\n     * This enables delimiters to be entered as data.\n     * </p>\n     *\n     * @param quote  the quote character to use\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setQuoteMatcher(final StrMatcher quote)",
        "implementation": "public StrTokenizer setQuoteMatcher(final StrMatcher quote) {\n        if (quote != null) {\n            this.quoteMatcher = quote;\n        }\n        return this;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setQuoteMatcher",
        "javadoc": "/**\n     * Sets the quote matcher to use.\n     * <p>\n     * The quote character is used to wrap data between the tokens.\n     * This enables delimiters to be entered as data.\n     * </p>\n     *\n     * @param quote  the quote matcher to use, null ignored\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public StrTokenizer setTrimmerMatcher(final StrMatcher trimmer)",
        "implementation": "public StrTokenizer setTrimmerMatcher(final StrMatcher trimmer) {\n        if (trimmer != null) {\n            this.trimmerMatcher = trimmer;\n        }\n        return this;\n    }",
        "called_methods": "",
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "setTrimmerMatcher",
        "javadoc": "/**\n     * Sets the matcher for characters to trim.\n     * <p>\n     * These characters are trimmed off on each side of the delimiter\n     * until the token or quote is found.\n     * </p>\n     *\n     * @param trimmer  the trimmer matcher to use, null ignored\n     * @return this, to enable chaining\n     */"
    },
    {
        "signature": "public int size()",
        "implementation": "public int size() {\n        checkTokenized();\n        return tokens.length;\n    }",
        "called_methods": [
            "checkTokenized"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "size",
        "javadoc": "/**\n     * Gets the number of tokens found in the String.\n     *\n     * @return The number of matched tokens\n     */"
    },
    {
        "signature": "protected List<String> tokenize(final char[] srcChars, final int offset, final int count)",
        "implementation": "protected List<String> tokenize(final char[] srcChars, final int offset, final int count) {\n        if (srcChars == null || count == 0) {\n            return Collections.emptyList();\n        }\n        final StrBuilder buf = new StrBuilder();\n        final List<String> tokenList = new ArrayList<>();\n        int pos = offset;\n\n        // loop around the entire buffer\n        while (pos >= 0 && pos < count) {\n            // find next token\n            pos = readNextToken(srcChars, pos, count, buf, tokenList);\n\n            // handle case where end of string is a delimiter\n            if (pos >= count) {\n                addToken(tokenList, StringUtils.EMPTY);\n            }\n        }\n        return tokenList;\n    }",
        "called_methods": [
            "emptyList",
            "readNextToken",
            "addToken"
        ],
        "repository": "commons-text-master-docbyai",
        "source": "commons-text-master-docbyai\\src\\main\\java\\org\\apache\\commons\\text\\StrTokenizer.java",
        "name": "tokenize",
        "javadoc": "/**\n     * Internal method to performs the tokenization.\n     * <p>\n     * Most users of this class do not need to call this method. This method\n     * will be called automatically by other (public) methods when required.\n     * </p>\n     * <p>\n     * This method exists to allow subclasses to add code before or after the\n     * tokenization. For example, a subclass could alter the character array,\n     * offset or count to be parsed, or call the tokenizer multiple times on\n     * multiple strings. It is also be possible to filter the results.\n     * </p>\n     * <p>\n     * {@code StrTokenizer} will always pass a zero offset and a count\n     * equal to the length of the array to this method, however a subclass\n     * may pass other values, or even an entirely different array.\n     * </p>\n     *\n     * @param srcChars  the character array being tokenized, may be null\n     * @param offset  the start position within the character array, must be valid\n     * @param count  the number of characters to tokenize, must be valid\n     * @return The modifiable list of String tokens, unmodifiable if null array or zero count\n     */"
    }
]